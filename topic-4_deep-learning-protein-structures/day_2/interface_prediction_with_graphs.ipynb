{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --use-pep517 lightning torch torch-geometric tensorboard nbformat \"jsonargparse[signatures]\" ipywidgets tabulate\n",
    "!pip install git+https://github.com/a-r-j/graphein.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import graphein\n",
    "graphein.verbose(enabled=False)\n",
    "from graphein.protein.config import ProteinGraphConfig\n",
    "from graphein.protein.graphs import construct_graph\n",
    "from graphein.protein.features.nodes import amino_acid as graphein_nodes\n",
    "from graphein.protein import edges as graphein_edges\n",
    "from graphein.protein.subgraphs import extract_subgraph\n",
    "from graphein.protein.visualisation import plotly_protein_structure_graph\n",
    "from functools import partial\n",
    "from matplotlib import colormaps\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY FOR COLAB!\n",
    "import gdown\n",
    "gdown.download(id=\"1assQw7HSd7ErD0xOWqakLcm-o_5X-xL6\", output=\"hackathon_data.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip hackathon_data.zip\n",
    "!mv \"scicore/home/schwede/durair0000/projects/vib-ai-course/ml-ai-summer-school-vib/1_graphs_interface/data/hackathon_data\" .\n",
    "!rm -rf scicore/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = Path(\"../data/hackathon_data/\")\n",
    "DATA_DIR = Path(\"hackathon_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_DIR / \"data.csv\")\n",
    "df[\"holo_filenames\"] = df[\"pinder_id\"].apply(lambda x: f\"{x.split('--')[0]}-R--{x.split('--')[1]}-L.pdb\")\n",
    "df[\"holo_paths\"] = df[[\"split\", \"pinder_id\", \"holo_filenames\"]].apply(lambda x: DATA_DIR / x[\"split\"] / x[\"pinder_id\"] / x[\"holo_filenames\"], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filename = df[\"holo_paths\"].values[0]\n",
    "test_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting proteins to featurized graphs\n",
    "\n",
    "The [graphein](https://graphein.ai/) library provides functionality for producing a number of types of graph-based representations of proteins. We'll use it to construct [NetworkX](https://github.com/networkx/networkx) graphs from protein structures, extract interface residues, and to featurise the nodes and edges of the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the node features implemented in `graphein.protein.features.nodes.amino_acid`, but there's many more kinds of node features available in the library (see the full [API](https://graphein.ai/modules/graphein.protein.html#features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "graph_config = ProteinGraphConfig(\n",
    "    verbose=True,\n",
    "    node_metadata_functions = [graphein_nodes.amino_acid_one_hot, graphein_nodes.meiler_embedding],\n",
    "    edge_construction_functions = [graphein_edges.add_peptide_bonds, partial(graphein_edges.add_distance_threshold, \n",
    "                                                                             threshold=8.0, \n",
    "                                                                             long_interaction_threshold=2)]\n",
    "                                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "graph = construct_graph(path=test_filename, \n",
    "                        config=graph_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a graph object consisting of nodes and edges, each associated with the attributes we've specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for (node, node_data) in graph.nodes(data=True):\n",
    "  print(\"Node:\", node)\n",
    "  print(\"Node attributes:\", node_data)\n",
    "  if i > 5:\n",
    "    break\n",
    "  i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for (start_node, end_node, edge_data) in graph.edges(data=True):\n",
    "  print(f\"Edge between {start_node} and {end_node}\")\n",
    "  print(\"Edge attributes:\", edge_data)\n",
    "  if i > 5:\n",
    "    break\n",
    "  i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "p = plotly_protein_structure_graph(\n",
    "    graph,\n",
    "    colour_edges_by=\"kind\",\n",
    "    colour_nodes_by='chain_id',\n",
    "    label_node_ids=False,\n",
    "    node_size_multiplier=1\n",
    "    )\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract interface residues from this graph by checking for edges between chains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "interface_residues = set()\n",
    "for source, target, kind in graph.edges(data=True):\n",
    "    if 'distance_threshold' in kind['kind']:\n",
    "        source_chain = source.split(\":\")[0]\n",
    "        target_chain = target.split(\":\")[0]\n",
    "        if source_chain != target_chain:\n",
    "            if source_chain == \"R\":\n",
    "                interface_residues.add(source)\n",
    "            elif target_chain == \"R\":\n",
    "                interface_residues.add(target)\n",
    "interface_residues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This information can be added to the graph as an `interface_label` node feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for node, data in graph.nodes(data=True):\n",
    "  if node in interface_residues:\n",
    "    data['interface_label'] = 1\n",
    "  else:\n",
    "    data['interface_label'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see where the interface is for this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "p = plotly_protein_structure_graph(\n",
    "    graph,\n",
    "    colour_edges_by='kind',\n",
    "    colour_nodes_by='interface_label',\n",
    "    label_node_ids=False,\n",
    "    edge_color_map=colormaps['Pastel2'],\n",
    "    node_size_multiplier=1\n",
    "    )\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our task is to predict interface residues given just one input chain, we'll extract the subgraph for the chain of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain_subgraph = extract_subgraph(graph, chains=\"R\")\n",
    "\n",
    "p = plotly_protein_structure_graph(\n",
    "    chain_subgraph,\n",
    "    colour_edges_by=\"kind\",\n",
    "    colour_nodes_by=\"interface_label\",\n",
    "    label_node_ids=False,\n",
    "    edge_color_map=colormaps['Pastel2'],\n",
    "    plot_title=\"Peptide backbone graph. Nodes coloured by interface_label.\",\n",
    "    node_size_multiplier=1\n",
    "    )\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We put all this together in a function to use in the later notebooks. Feel free to add other node features, edge types, and edge features to your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_graph(path, chain):\n",
    "    graph_config = ProteinGraphConfig(\n",
    "        node_metadata_functions = [graphein_nodes.amino_acid_one_hot, graphein_nodes.meiler_embedding],\n",
    "        edge_construction_functions = [graphein_edges.add_peptide_bonds, \n",
    "                                       partial(graphein_edges.add_distance_threshold, \n",
    "                                               threshold=8.,\n",
    "                                               long_interaction_threshold=2)],\n",
    "    )\n",
    "    graph = construct_graph(path=path, config=graph_config, verbose=False)\n",
    "    interface_residues = set()\n",
    "    for source, target, kind in graph.edges(data=True):\n",
    "        c1, c2 = source.split(\":\")[0], target.split(\":\")[0]\n",
    "        if 'distance_threshold' in kind['kind']:\n",
    "            if c1 != c2:\n",
    "                if c1 == chain:\n",
    "                    interface_residues.add(source)\n",
    "                elif c2 == chain:\n",
    "                    interface_residues.add(target)\n",
    "    graph = extract_subgraph(graph, chains=chain)\n",
    "    for node, data in graph.nodes(data=True):\n",
    "        if node in interface_residues:\n",
    "            data['interface_label'] = 1\n",
    "        else:\n",
    "            data['interface_label'] = 0\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "\n",
    "We can also add our own edge functions or node features that are not implemented in the graphein API. For example, we can calculate the solvent accessible surface area (SASA) for each residue and include it in as a node feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import PDBParser\n",
    "from Bio.PDB.SASA import ShrakeRupley\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # to ignore warnings when parsing pdb structures\n",
    "\n",
    "def add_sasa(path, graph, chain):\n",
    "    struct = PDBParser().get_structure(Path(path).stem, path)[0][chain] # Only get one chain\n",
    "    sr = ShrakeRupley()\n",
    "    sr.compute(struct, level=\"R\") # residue level\n",
    "    for _, data in graph.nodes(data=True):\n",
    "        # add SASA to node features\n",
    "        data['sasa'] = struct[data['residue_number']].sasa\n",
    "    return graph\n",
    "\n",
    "graph = load_graph(test_filename, \"R\")\n",
    "graph = add_sasa(test_filename, graph, \"R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for (node, node_data) in graph.nodes(data=True):\n",
    "    print(\"Node:\", node)\n",
    "    print(\"Node attributes:\", node_data)\n",
    "    if i > 5:\n",
    "        break\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sasa, interface_labels = [], []\n",
    "for (node, node_data) in graph.nodes(data=True):\n",
    "    sasa.append(node_data['sasa'])\n",
    "    interface_labels.append(node_data['interface_label'])\n",
    "data = {\n",
    "    \"sasa\": sasa,\n",
    "    \"interface_labels\": interface_labels\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.violinplot(x=\"interface_labels\", y=\"sasa\", data=data)\n",
    "plt.title(\"SASA between interface and non-interface residues\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What other node or edge features would you like to include in your graph?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting graphs to deep learning datasets\n",
    "\n",
    "Deep learning libraries like PyTorch, and by extension PyTorch-Geometric, have some standardized ways of handling data and datasets, in order to optimize the operations they perform on the various numeric features involved. In this notebook, we will see how to convert a graph into a torch `Data` object, which is the standard way of representing a graph in PyTorch-Geometric. Then we'll go from a single graph to a `Dataset` of graphs, which is the standard way of representing a dataset in PyTorch. And finally, we'll see how to wrap this `Dataset` into a Lightning `DataModule`, which is the standard way of handling data-related operations in PyTorch-Lightning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data \n",
    "\n",
    "We first need to make a torch `Data` object from our graphs. This is easily done with graphein's conversion functions, specifically the `GraphFormatConvertor`, where you can specify which features of the NetworkX graph you'd like to retain in the `Data` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphein.ml import GraphFormatConvertor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "            \"chain_id\",\n",
    "            \"coords\",\n",
    "            \"edge_index\",\n",
    "            \"node_id\",\n",
    "            \"residue_number\",\n",
    "            \"amino_acid_one_hot\",\n",
    "            \"meiler\",\n",
    "            \"interface_label\"\n",
    "]\n",
    "convertor = GraphFormatConvertor(src_format=\"nx\", # From NetworkX \n",
    "                                 dst_format=\"pyg\", # To PyTorch Geometric\n",
    "                                 columns=columns, # The columns to be used\n",
    "                                 verbose=None)\n",
    "graphein_graph = load_graph(test_filename, \"R\")\n",
    "torch_data = convertor(graphein_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(torch_data.node_id[:5], torch_data.interface_label[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_data.edge_index.T[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, here are the amino acid types across interface and non-interface residues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_amino_acids = [s.split(\":\")[1] for s in torch_data.node_id]\n",
    "\n",
    "data_with_aa = {\"amino acid\": extracted_amino_acids, \"interface labels\": torch_data.interface_label}\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.countplot(x=\"amino acid\", hue=\"interface labels\", data=data_with_aa, palette=\"Set2\")\n",
    "plt.title(\"Distribution of amino acids types across interface and non-interface residues\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Amino acid\")\n",
    "plt.legend(title=\"Interface label\", loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `to_networkx` function to convert the `Data` object back to a NetworkX graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "nx_graph_again = to_networkx(torch_data, \n",
    "                                   node_attrs=[\"chain_id\",\n",
    "                                               \"coords\",\n",
    "                                               \"node_id\",\n",
    "                                               \"residue_number\",\n",
    "                                               \"amino_acid_one_hot\",\n",
    "                                               \"meiler\",\n",
    "                                               \"interface_label\"],\n",
    "                                    to_undirected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = plotly_protein_structure_graph(\n",
    "    nx_graph_again,\n",
    "    colour_edges_by=None,\n",
    "    colour_nodes_by='interface_label',\n",
    "    label_node_ids=False,\n",
    "    node_size_multiplier=1\n",
    "    )\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "The `torch_geometric.data.Dataset` class is a standard way of representing a graph dataset in PyTorch. It is an abstract class that you can subclass to create your own dataset. The functions that need to be included are:\n",
    "\n",
    "- `download()`: this downloads the dataset (in our case from `dataset.txt`) and saves each data point (in our case as a pickle file containing the graphein graph that our `load_graph` function returns) in `self.raw_dir`.\n",
    "- `process()`: this processes the data from `self.raw_dir` to torch-geometric `Data` objects (as we did above), and saves them as `.pt` files in `self.processed_dir`.\n",
    "- property functions: `raw_file_names`, `processed_file_names` return the names of the raw pickle and processed pt files for each data point.\n",
    "- `len()`: this returns the number of graphs in the dataset\n",
    "- `get()`: this returns the `Data` object for a given index\n",
    "\n",
    "See the [documentation](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Dataset.html#torch_geometric.data.Dataset) for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from torch_geometric.data import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    \"\"\"\n",
    "    torch-geometric Dataset class for loading protein files as graphs.\n",
    "    \"\"\"\n",
    "    def __init__(self, root, paths: list):\n",
    "        columns = [\n",
    "            \"chain_id\",\n",
    "            \"coords\",\n",
    "            \"edge_index\",\n",
    "            \"kind\",\n",
    "            \"node_id\",\n",
    "            \"residue_number\",\n",
    "            \"amino_acid_one_hot\",\n",
    "            \"meiler\",\n",
    "            \"interface_label\",\n",
    "        ]\n",
    "        self.convertor = GraphFormatConvertor(src_format=\"nx\", dst_format=\"pyg\", columns=columns, verbose=None)\n",
    "        self.paths = []\n",
    "        for path in paths:\n",
    "            self.paths.append((path, path.stem.split(\"--\")[0], \"R\"))\n",
    "            self.paths.append((path, path.stem.split(\"--\")[1], \"L\"))\n",
    "        super(ProteinDataset, self).__init__(root)\n",
    "\n",
    "    def download(self):\n",
    "        for path, name, chain in tqdm(self.paths):\n",
    "            output = Path(self.raw_dir) / f'{name}-{chain}.pkl'\n",
    "            if not output.exists():\n",
    "                graphein_graph = load_graph(path, chain)\n",
    "                with open(output, \"wb\") as f:\n",
    "                    pickle.dump(graphein_graph, f)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [Path(self.raw_dir) / f\"{name}-{chain}.pkl\" for _, name, chain in self.paths]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [Path(self.processed_dir) / f\"{name}-{chain}.pt\" for _, name, chain in self.paths]\n",
    "\n",
    "    def process(self):\n",
    "        for _, name, chain in tqdm(self.paths):\n",
    "            output = Path(self.processed_dir) / f'{name}-{chain}.pt'\n",
    "            if not output.exists():\n",
    "                with open(Path(self.raw_dir) / f\"{name}-{chain}.pkl\", \"rb\") as f:\n",
    "                    graphein_graph = pickle.load(f)\n",
    "                torch_data = self.convertor(graphein_graph)\n",
    "                torch.save(torch_data, output)\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(self.processed_file_names[idx], weights_only=False)\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = df[\"holo_paths\"].values[:10]\n",
    "dataset = ProteinDataset(root='./test_data', paths=paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_amino_acids = []\n",
    "all_interface_labels = []\n",
    "\n",
    "for torch_graph in dataset:\n",
    "    extracted_amino_acids = [s.split(\":\")[1] for s in torch_graph.node_id]\n",
    "    all_amino_acids.extend(extracted_amino_acids)\n",
    "    all_interface_labels.extend(torch_graph.interface_label.tolist())\n",
    "\n",
    "data_with_aa = {\n",
    "    \"amino acid\": all_amino_acids,\n",
    "    \"interface labels\": all_interface_labels\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.countplot(x=\"amino acid\", hue=\"interface labels\", data=data_with_aa, palette=\"Set2\")\n",
    "plt.title(\"Distribution of amino acids types across interface and non-interface residues\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Amino acid\")\n",
    "plt.legend(title=\"Interface label\", loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphein also has a built-in `ProteinGraphDataset` class that combines these steps. It also has some nice features like \n",
    "- the ability to load a dataset of proteins from both the PDB or AlphaFold Database directory of PDB files\n",
    "- the ability to apply custom transformations from your bioinformatics tools of choice to the PDB files (with the `pdb_transform` argument)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataModule\n",
    "\n",
    "Now that we have our `Dataset` ready, we need to specificy how the `Data` objects within the created Dataset are split into training, validation and test sets. This is where PyTorch Lightning's DataModule comes in ([documentation](https://lightning.ai/docs/pytorch/stable/data/datamodule.html)). The `DataModule` is a class that encapsulates the logic for loading, batching and splitting the data. It's a way of separating the logic for data loading and batching separate from both the data ingestion and the model and training logic, which makes the code more modular and easier to maintain. It also makes it easier to switch between different datasets and data loading strategies.\n",
    "\n",
    "To define a `DataModule` the following methods are necessary:\n",
    "- `prepare_data()` - this defines the downloading and IO operations that are generally slower and need to only be run once. In our case it just runs the Dataset function once to download and process all the pickle and pt files. This is called once in the beginning of training so all the future calls of Dataset in setup (which is called on every node/process) just loads the data from the saved files.\n",
    "- `setup()` - this defines how to split the dataset. It also takes a `stage` argument (one of `fit,validate,test,predict`).\n",
    "- `train_dataloader()` - this returns the `DataLoader` for the training data\n",
    "\n",
    "and the following are optional:\n",
    "- `val_dataloader()` - this returns the `DataLoader` for the validation data\n",
    "- `test_dataloader()` - this returns the `DataLoader` for the test data\n",
    "- `predict_dataloader()` - this returns the `DataLoader` for the inference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch import LightningDataModule\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "class ProteinGraphDataModule(LightningDataModule):\n",
    "    def __init__(self, root, dataset_file, batch_size=8):\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.dataset = pd.read_csv(dataset_file)\n",
    "        self.dataset[\"holo_filenames\"] = self.dataset[\"pinder_id\"].apply(lambda x: f\"{x.split('--')[0]}-R--{x.split('--')[1]}-L.pdb\")\n",
    "        self.dataset[\"holo_paths\"] = self.dataset[[\"split\", \"pinder_id\", \"holo_filenames\"]].apply(lambda x: dataset_file.parent / x[\"split\"] / x[\"pinder_id\"] / x[\"holo_filenames\"], axis=1)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def prepare_data(self):\n",
    "        for split in self.dataset[\"split\"].unique():\n",
    "            ProteinDataset(root=self.root, paths=self.dataset[self.dataset[\"split\"] == split][\"holo_paths\"].values[:10])\n",
    "    \n",
    "    def setup(self, stage):\n",
    "        self.train = ProteinDataset(root=self.root, paths=self.dataset[self.dataset[\"split\"] == \"train\"][\"holo_paths\"].values[:10])\n",
    "        self.val = ProteinDataset(root=self.root, paths=self.dataset[self.dataset[\"split\"] == \"val\"][\"holo_paths\"].values[:10])\n",
    "        self.test = ProteinDataset(root=self.root, paths=self.dataset[self.dataset[\"split\"] == \"test\"][\"holo_paths\"].values[:10])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DataModule` is now ready, give it a try and loop through the dataloader to see how they work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = ProteinGraphDataModule(\"./test_data\", DATA_DIR / \"data.csv\")\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup(\"fit\")\n",
    "\n",
    "train_loader = datamodule.train_dataloader()\n",
    "example_train_protein = datamodule.train[0]\n",
    "example_train_batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an example train data point (`example_train_protein`) but training is almost always done on batches of data points controlled by the `batch_size`. This batch size defines the number of input graphs looked at in each iteration of the training process (one forward and backward pass). It has a trade-off between the speed of the training and the generalizability of the model.\n",
    "\n",
    "In the graph neural network setting, a batch essentially combines all the graphs of the individual proteins into a bigger graph, with an additional batch attribute that specifies which protein each node belongs to. Since there are no edges between the different proteins, training on this batch graph is equivalent to training on the individual graphs separately, since no information flows between the different proteins. This is what is returned by the `train_dataloader` of the `DataModule`, in `example_train_batch`. \n",
    "\n",
    "Let's check what each of variables contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_train_protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_train_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch-Geometric models and layers\n",
    "\n",
    "Now that we have our data ready, we'll take a look at some of the different architectures and building block layers that are implemented in the `torch-geometric` library, and how they can be used to build and train models for graph-based tasks.\n",
    "\n",
    "- [torch_geometric.nn](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html) has a variety of graph layers that can be used to build custom GNN architectures. These include:\n",
    "    - [Convolutional layers](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#convolutional-layers): These define how the message passing step is accomplished across edges in the graph. `GCNConv` is a simple example of a graph convolution layer, while `GATConv` is a more complex example with attention mechanisms.\n",
    "    - [Aggregation Operators](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#aggregation-operators): These define how messages are aggregated at each node. \n",
    "    - [Pooling layers](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#id45): These define how nodes are aggregated into a single node.\n",
    "\n",
    "- [torch_geometric.nn.models](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#models) has more complex model architectures with a variety of of these layers already defined and combined inside.\n",
    "- The [PyGModelHubMixin](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.model_hub.PyGModelHubMixin) class can be used to load pre-trained models or other model architectures from the [HuggingFace Model Hub](https://huggingface.co/models?pipeline_tag=graph-ml&sort=trending)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph neural network layers\n",
    "\n",
    "Here's how we would define a graph convolutional layer that takes amino acid one hot embeddings as input node features along with the edge index to define the graph, and converts them to a 64-dimensional embedding via convolution operations across the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric import nn as graph_nn\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = graph_nn.GCNConv(in_channels=20, out_channels=1)\n",
    "example_output = layer(example_train_batch.amino_acid_one_hot.float(), example_train_batch.edge_index)\n",
    "example_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try out some of the other layers in the torch_geometric.nn module!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph neural network models\n",
    "\n",
    "We can also try out some of the pre-defined models in the `torch_geometric.nn.models` module, such as the `GAT` model which applies a series of `GATv2Conv` layers that uses attention mechanisms to weight the importance of different nodes in the graph when aggregating information from neighbors, followed by a Linear layer to convert the node embeddings to a 64-dimensional output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = graph_nn.GAT(in_channels=20,\n",
    "                     hidden_channels=32,\n",
    "                     num_layers=3,\n",
    "                     heads=2,\n",
    "                     out_channels=64,\n",
    "                     dropout=0.01,\n",
    "                     jk=\"last\", \n",
    "                     v2=True)\n",
    "print(graph_nn.summary(model, example_train_batch.amino_acid_one_hot.float(), example_train_batch.edge_index))\n",
    "print(model(example_train_batch.amino_acid_one_hot.float(), example_train_batch.edge_index).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try out some of the other models in the torch_geometric.nn module!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine layers into custom architectures. Here is an example of a simple architecture that uses a GATConv layer and a GCNConv layer with some activation functions in between, and finally a linear layer to convert the 64-dimensional node embeddings to one value per node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = graph_nn.Sequential('x, edge_index', [\n",
    "    (graph_nn.GATConv(in_channels=20, out_channels=64, heads=2, concat=False), 'x, edge_index -> x'),\n",
    "    nn.ReLU(inplace=True),\n",
    "    (graph_nn.GCNConv(in_channels=64, out_channels=64), 'x, edge_index -> x'),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(64, 1),\n",
    "])\n",
    "\n",
    "print(graph_nn.summary(model, example_train_batch.amino_acid_one_hot.float(), example_train_batch.edge_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining losses\n",
    "\n",
    "In order to train such models with our data for our task of interface residue prediction, we need to define a loss function that takes the output of the model (the prediction) and the target labels and computes a loss value that the optimizer can use to update the model parameters. A typical choice for binary classification tasks is the binary cross entropy loss, which is implemented in PyTorch as `torch.nn.BCEWithLogitsLoss`. This loss function takes the raw output of the model and the target labels, and applies the sigmoid function to the model output to get the predicted probabilities, and then computes the binary cross entropy loss between the predicted probabilities and the target labels, defined as\n",
    "\n",
    "$$\n",
    "\\text{loss} = -\\frac{1}{N} \\sum_{i=1}^N \\left[ y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\right]\n",
    "$$\n",
    "\n",
    "where $N$ is the number of residues, $y_i$ is the target label for residue $i$ (1 if it's an interface residue, 0 if not), and $p_i$ is the predicted probability for residue $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.BCEWithLogitsLoss()(model(example_train_batch.amino_acid_one_hot.float(), example_train_batch.edge_index), \n",
    "                       example_train_batch.interface_label.view(-1, 1).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model\n",
    "\n",
    "Given a model that predicts interface probabilities and a loss that compared them with the true interface labels, what we now need is a training loop that will iterate over the training data in batches, compute the loss, and use an optimizer to update the model parameters based on the loss value.\n",
    "\n",
    "All of this is encapsulated within the `LightningModule` class in PyTorch Lightning.\n",
    "\n",
    "![](https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/pl-walk-lit-module.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch import LightningModule\n",
    "\n",
    "class InterfaceModule(LightningModule):\n",
    "    \"\"\"\n",
    "    LightningModule wrapping a GAT model.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=20, hidden_channels=32, num_layers=2, heads=2, out_channels=1, dropout=0.01, jk=\"last\"):\n",
    "        super().__init__()\n",
    "        self.model = graph_nn.GAT(in_channels=in_channels,\n",
    "                         hidden_channels=hidden_channels,\n",
    "                         num_layers=num_layers,\n",
    "                         heads=heads,\n",
    "                         out_channels=out_channels,\n",
    "                         dropout=dropout,\n",
    "                         jk=jk, v2=True)\n",
    "        self.loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, node_attributes, edge_index):\n",
    "        return self.model(node_attributes, edge_index)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        out = self(batch.amino_acid_one_hot.float(), batch.edge_index)\n",
    "        loss = self.loss_function(out, batch.interface_label.float().view(-1, 1))\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, sync_dist=True,\n",
    "                 batch_size=batch.batch_size)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "      return torch.optim.Adam(params=self.model.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Trainer` class then combines the training loop defined in the LightningModule with the data loading functions in the LightningDataModule. We set the `max_epochs` to 5, meaning that the training loop will iterate over the entire training data 5 times, updating the model parameters with each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch import Trainer\n",
    "\n",
    "trainer = Trainer(max_epochs=10, accelerator='cpu')\n",
    "model = InterfaceModule()\n",
    "datamodule = ProteinGraphDataModule(\"./test_data\", DATA_DIR / \"data.csv\")\n",
    "trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations, your model is training!**\n",
    "\n",
    "The next step is to monitor the performance of the model on the validation data (and maybe even stop training when the performance stops improving). We'd probably like to see some metrics beyond the loss value (like accuracy, precision, recall) and how those change over time, both on the training data and the validation data to make sure the model is learning something useful and not overfitting. All of this needs more complex logging and monitoring."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
